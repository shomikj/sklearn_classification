{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using scikit-learn\n",
    "\n",
    "This notebook overviews widely-used supervised ML models in scikit-learn, specifically for classification problems. \n",
    "- **Supervised Learning**: given a dataset of labeled training examples\n",
    "- **Classification Problem**: assign a discrete class based on certain input features\n",
    "    - *Binary Classification*: cancer or no cancer, cats vs dogs\n",
    "    - *Multiclass Classifcation*: handwritten digits, cats vs dogs vs monkeys \n",
    "- **scikit-learn**: Simple Python ML Library, https://scikit-learn.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "**UCI Heart Disease Dataset**: https://www.kaggle.com/ronitf/heart-disease-uci<br/>\n",
    "Goal: presense/absence of heart disease based the following health-related features\n",
    "\n",
    "- *age*: age in years \n",
    "- *sex*: (1 = male; 0 = female) \n",
    "- *cp*: chest pain type \n",
    "- *trestbps*: resting blood pressure (in mm Hg on admission to the hospital) \n",
    "- *chol*: serum cholestoral in mg/dl \n",
    "- *fbs*: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) \n",
    "- *restecg*: resting electrocardiographic results \n",
    "- *thalach*: maximum heart rate achieved \n",
    "- *exang*: exercise induced angina (1 = yes; 0 = no) \n",
    "- *oldpeak*: ST depression induced by exercise relative to rest \n",
    "- *slope*: the slope of the peak exercise ST segment \n",
    "- *ca*: number of major vessels (0-3) colored by flourosopy \n",
    "- *thal*: 3 = normal; 6 = fixed defect; 7 = reversable defect \n",
    "- *target*: have disease or not (1=yes, 0=no)\n",
    "\n",
    "**Data Preprocessing Techniques**:\n",
    "- *One-Hot Encoding*: for categorical features\n",
    "    - for example, the gender feature above is coded as (1 = male; 0 = female) \n",
    "    - this may cause some models to learn associations like male > female \n",
    "    - instead, we one-hot encode and create 2 features: is_female, is_male\n",
    "    - at a low level, this looks like: [1 0 1] => [[0 1] [1 0] [0 1]] \n",
    "- *Feature Normalization*: scale from 0 to 1\n",
    "    - the range of values for different features usually varies widely\n",
    "    - this may cause problems if models try to compare features\n",
    "    - thus, we rescale all features from 0 to 1 using min-max normalization\n",
    "    - for a feature x, the formula is: x' = (x - min(x)) / (max(x) - min(x))\n",
    "    \n",
    "**Data for Models**:\n",
    "- *Training Data*: examples used to train the model\n",
    "- *Testing Data*: examples used to test the model, separate from training data\n",
    "- We randomly choose 75% of all data for training, and the remaining 25% for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External script provides X_train, y_train, X_test, y_test Pandas Dataframes. \n",
    "# X_train: features of training examples  \n",
    "# y_train: labels of training examples\n",
    "# X_test: features of testing examples  \n",
    "# y_test: labels of testing examples\n",
    "\n",
    "%run -i load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original Dataset \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>cp_2</th>\n",
       "      <th>cp_3</th>\n",
       "      <th>thal_0</th>\n",
       "      <th>thal_1</th>\n",
       "      <th>thal_2</th>\n",
       "      <th>thal_3</th>\n",
       "      <th>slope_0</th>\n",
       "      <th>slope_1</th>\n",
       "      <th>slope_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.347032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.618321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.267123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.503817</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0.326484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.748092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.454338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.633588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.415525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  sex  trestbps      chol  fbs  restecg   thalach  exang  \\\n",
       "153  0.770833  0.0  0.490566  0.347032  0.0      0.0  0.618321    0.0   \n",
       "23   0.666667  1.0  0.528302  0.267123  1.0      0.5  0.503817    1.0   \n",
       "263  0.708333  0.0  0.132075  0.326484  0.0      0.5  0.748092    1.0   \n",
       "110  0.729167  0.0  0.811321  0.454338  0.0      0.5  0.633588    1.0   \n",
       "81   0.333333  1.0  0.320755  0.415525  0.0      0.0  0.755725    0.0   \n",
       "\n",
       "      oldpeak    ca   ...     cp_1  cp_2  cp_3  thal_0  thal_1  thal_2  \\\n",
       "153  0.000000  0.25   ...      0.0   1.0   0.0     0.0     0.0     1.0   \n",
       "23   0.161290  0.00   ...      0.0   1.0   0.0     0.0     0.0     1.0   \n",
       "263  0.290323  0.50   ...      0.0   0.0   0.0     0.0     0.0     1.0   \n",
       "110  0.000000  0.00   ...      0.0   0.0   0.0     0.0     0.0     1.0   \n",
       "81   0.000000  0.00   ...      1.0   0.0   0.0     0.0     0.0     1.0   \n",
       "\n",
       "     thal_3  slope_0  slope_1  slope_2  \n",
       "153     0.0      0.0      1.0      0.0  \n",
       "23      0.0      0.0      1.0      0.0  \n",
       "263     0.0      0.0      1.0      0.0  \n",
       "110     0.0      0.0      0.0      1.0  \n",
       "81      0.0      0.0      0.0      1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features of training examples, after preprocessing \n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation Metrics**:\n",
    "- *Accuracy*: overall proportion of accurate predictions\n",
    "- *AUROC*: probability a classifier will rank a randomly chosen positive example higher than a randomly chosen negative example \n",
    "- *Precision*: proportion of predictions of a given class that are correct\n",
    "- *Recall*: proportion of actual instances of a given class that are predicted correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors (k-NN)**: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "- k-NN outputs the most common class among a given test element's *k* closest training examples (nearest neighbors) \n",
    "- \"closeness\" measured using feature similarity: how similar two elements are on the basis of their features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7850877192982456\n",
      "AUROC:  0.8818471833177716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76       102\n",
      "           1       0.81      0.80      0.80       126\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       228\n",
      "   macro avg       0.78      0.78      0.78       228\n",
      "weighted avg       0.79      0.79      0.79       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "scores = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, pred))\n",
    "print('AUROC: ', roc_auc_score(y_test, scores))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes**: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "- What is the probability that a given test element belongs to a class on the basis of its features?\n",
    "- Conditional probabilities calculated using training examples and Bayes' Rule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7982456140350878\n",
      "AUROC:  0.8796296296296298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       102\n",
      "           1       0.81      0.83      0.82       126\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       228\n",
      "   macro avg       0.80      0.80      0.80       228\n",
      "weighted avg       0.80      0.80      0.80       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB(var_smoothing=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "scores = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, pred))\n",
    "print('AUROC: ', roc_auc_score(y_test, scores))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Trees**: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- Decision trees embody a flowchart-like structure; sequential, hierarchical decisions are used to choose a class for a given example. \n",
    "- Decision rules are usually based on feature thresholds (i.e. cholesterol level > X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7236842105263158\n",
      "AUROC:  0.7903439153439153\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69       102\n",
      "           1       0.75      0.75      0.75       126\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       228\n",
      "   macro avg       0.72      0.72      0.72       228\n",
      "weighted avg       0.72      0.72      0.72       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=3, min_samples_leaf=0.1, max_features=None)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "scores = clf.predict_proba(X_test)[:,1]   \n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, pred))\n",
    "print('AUROC: ', roc_auc_score(y_test, scores))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "- Logistic Regression finds a boundary (hyperplane) to distiguish classes in feature space \n",
    "- Feature Space: n-dimensional space (where n is the number of features); the features of a given example determine its coordinates in the n-dimensional space. \n",
    "- In comparision to SVM, Logistic Regression finds the boundary that maximizes the likelihood that a random data point is classified correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7807017543859649\n",
      "AUROC:  0.8765172735760971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76       102\n",
      "           1       0.82      0.78      0.80       126\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       228\n",
      "   macro avg       0.78      0.78      0.78       228\n",
      "weighted avg       0.78      0.78      0.78       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(penalty='l2', solver='liblinear', C=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "scores = clf.predict_proba(X_test)[:,1]   \n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, pred))\n",
    "print('AUROC: ', roc_auc_score(y_test, scores))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machines (SVM)**: https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
    "\n",
    "- SVM finds a boundary (hyperplane) to distiguish classes in feature space \n",
    "- Feature Space: n-dimensional space (where n is the number of features); the features of a given example determine its coordinates in the n-dimensional space. \n",
    "- In comparision to logistic regression, SVM finds the boundary with the widest possible separating margin between the classes in the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(penalty='l2', C=0.01, dual=False)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "scores = clf.decision_function(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, pred))\n",
    "print('AUC: ', roc_auc_score(y_test, scores))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch\n",
    "**Gridsearch**: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "- *Hyperparamters*: parameters of the model that are chosen ahead of time and that can be tweaked during successive trials to improve performance.\n",
    "- *Gridsearch*: process to determine the optimal hyperparameter values for a given model\n",
    "- *K-Fold Cross Validation*: evaluate specific hyperparameters by training and testing on different folds of the training data (only testing data for final evaluation, after tuning hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'weights': 'distance', 'n_neighbors': 10} \n",
      "\n",
      "Accuracy:  0.7850877192982456\n",
      "AUROC:  0.8818471833177716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76       102\n",
      "           1       0.81      0.80      0.80       126\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       228\n",
      "   macro avg       0.78      0.78      0.78       228\n",
      "weighted avg       0.79      0.79      0.79       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base_clf = neighbors.KNeighborsClassifier()\n",
    "parameters = {'n_neighbors': [1, 2, 5, 10, 15, 25], 'weights': ['uniform', 'distance']}\n",
    "\n",
    "clf = GridSearchCV(base_clf, parameters, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Best Hyperparameters: ', clf.best_params_, '\\n')\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "scores = clf.predict_proba(X_test)[:,1]   \n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, pred))\n",
    "print('AUROC: ', roc_auc_score(y_test, scores))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods\n",
    "\n",
    "**Ensemble Methods**: https://scikit-learn.org/stable/modules/ensemble.html <br/>\n",
    "Ensemble methods combine the predictions of several base classifiers, which helps improve generalizability / robustness over a single classifier. There are two common approaches:\n",
    "- *Averaging Methods*: build several classifiers independently and average their predictions\n",
    "- *Boosting Methods*: build several classifiers sequentially, where each new classifier tries to improve the previous one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "\n",
    "- A random forest is an averaging ensemble method that combines several decision tree classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'min_samples_leaf': 0.1, 'max_depth': 5, 'min_samples_split': 0.1, 'n_estimators': 10} \n",
      "\n",
      "Accuracy:  0.7456140350877193\n",
      "AUROC:  0.8569872393401805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70       102\n",
      "           1       0.75      0.81      0.78       126\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       228\n",
      "   macro avg       0.74      0.74      0.74       228\n",
      "weighted avg       0.75      0.75      0.74       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base_clf = RandomForestClassifier(n_estimators=100,\n",
    "                             max_features=None, \n",
    "                             min_samples_leaf=1,\n",
    "                             min_samples_split=2)\n",
    "parameters = {'n_estimators': [10, 100], 'min_samples_split': [0.1, 2], 'min_samples_leaf': [0.1, 1], 'max_depth': [1, 3, 5]}\n",
    "\n",
    "clf = GridSearchCV(base_clf, parameters, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Best Hyperparameters: ', clf.best_params_, '\\n')\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "scores = clf.predict_proba(X_test)[:,1]   \n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, pred))\n",
    "print('AUROC: ', roc_auc_score(y_test, scores))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosted Decision Trees (GBDT)**: \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n",
    "\n",
    "- GBDT is a boosting ensemble method that combines several decision tree classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'min_samples_leaf': 0.1, 'max_depth': 1, 'min_samples_split': 0.1, 'n_estimators': 100} \n",
      "\n",
      "Accuracy:  0.7807017543859649\n",
      "AUROC:  0.8640678493619671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       102\n",
      "           1       0.79      0.83      0.81       126\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       228\n",
      "   macro avg       0.78      0.78      0.78       228\n",
      "weighted avg       0.78      0.78      0.78       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base_clf = GradientBoostingClassifier()\n",
    "parameters = {'n_estimators': [10, 100], 'min_samples_split': [0.1, 2], 'min_samples_leaf': [0.1, 1], 'max_depth': [1, 3, 5]}\n",
    "\n",
    "clf = GridSearchCV(base_clf, parameters, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Best Hyperparameters: ', clf.best_params_, '\\n')\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "scores = clf.predict_proba(X_test)[:,1]   \n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, pred))\n",
    "print('AUROC: ', roc_auc_score(y_test, scores))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voting**: \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier\n",
    "\n",
    "- Voting is an averaging ensemble method that combines several classifiers of different types.\n",
    "- The example here uses voting with k-NN, GBDT, and Random Forests.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rf__n_estimators': 10, 'gb__min_samples_split': 2, 'gb__min_samples_leaf': 0.1, 'gb__n_estimators': 10, 'gb__max_depth': 1, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'knn__n_neighbors': 10, 'rf__max_depth': 3}\n",
      "Accuracy:  0.8026315789473685\n",
      "AUROC:  0.885932150638033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.78       102\n",
      "           1       0.81      0.83      0.82       126\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       228\n",
      "   macro avg       0.80      0.80      0.80       228\n",
      "weighted avg       0.80      0.80      0.80       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf1 = neighbors.KNeighborsClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = GradientBoostingClassifier(max_depth=1, min_samples_split=0.1)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('gb', clf3)], voting='soft')\n",
    "\n",
    "# We can tune individual parameters of each classifier using gridsearch as follows \n",
    "params = {'knn__n_neighbors': [5, 10, 25], \n",
    "          'rf__n_estimators': [10, 100], 'rf__min_samples_split': [0.1, 2], 'rf__min_samples_leaf': [0.1, 1], 'rf__max_depth': [1, 3, 5],\n",
    "          'gb__n_estimators': [10, 100], 'gb__min_samples_split': [0.1, 2], 'gb__min_samples_leaf': [0.1, 1], 'gb__max_depth': [1, 3, 5]}\n",
    "\n",
    "clf = GridSearchCV(voting_clf, params, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "scores = clf.predict_proba(X_test)[:,1]   \n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, pred))\n",
    "print('AUROC: ', roc_auc_score(y_test, scores))\n",
    "print(classification_report(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:caispp]",
   "language": "python",
   "name": "conda-env-caispp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
